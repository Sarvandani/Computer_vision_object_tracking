{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l53Pi-yC4m-L"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from google.colab import drive\n",
        "import urllib.request  # Add this import\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Mount Google Drive to access files\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Replace the video_url with the sharable link of video file in Google Drive\n",
        "video_url = 'https://drive.google.com/uc?id=1nOI6pIpUJ38lLSaz7Jv60exiwtvaifGW'\n",
        "\n",
        "# Download the video from the URL and save it as 'video.mp4' in the current directory\n",
        "video_file = \"video.mp4\"\n",
        "urllib.request.urlretrieve(video_url, video_file)\n",
        "\n",
        "# Open the video file for reading\n",
        "video_capture = cv2.VideoCapture(video_file)\n",
        "\n",
        "# Load the YOLO model\n",
        "model_url = \"https://tfhub.dev/tensorflow/ssd_mobilenet_v2/2\"  # Use a different version of the YOLO model\n",
        "yolo_model = hub.load(model_url)\n",
        "\n",
        "# Alternative implementation of CentroidTracker\n",
        "class CentroidTracker:\n",
        "    def __init__(self):\n",
        "        self.next_object_id = 0\n",
        "        self.objects = {}\n",
        "\n",
        "    def update(self, input_centroids):\n",
        "        new_objects = {}\n",
        "\n",
        "        for centroid in input_centroids:\n",
        "            object_id = self.next_object_id\n",
        "            self.next_object_id += 1\n",
        "            new_objects[object_id] = centroid\n",
        "\n",
        "        self.objects = new_objects\n",
        "        return self.objects\n",
        "\n",
        "# Initialize the CentroidTracker\n",
        "centroid_tracker = CentroidTracker()\n",
        "\n",
        "while True:\n",
        "    ret, frame = video_capture.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "    # Convert the frame to RGB format\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Perform object detection using YOLO\n",
        "    input_image = tf.image.convert_image_dtype(frame_rgb, dtype=tf.uint8)  # Convert frame to tf.uint8\n",
        "    input_image = tf.expand_dims(input_image, axis=0)  # Add batch dimension\n",
        "    outputs = yolo_model(input_image)\n",
        "    boxes = outputs[\"detection_boxes\"]\n",
        "    scores = outputs[\"detection_scores\"]\n",
        "\n",
        "    # Extract centroids from the detected boxes\n",
        "    input_centroids = []\n",
        "    for box, score in zip(boxes[0], scores[0]):\n",
        "        if score > 0.3:  # Consider boxes with different scores\n",
        "            ymin, xmin, ymax, xmax = box\n",
        "            x_center = (xmin + xmax) / 2\n",
        "            y_center = (ymin + ymax) / 2\n",
        "            centroid = (int(x_center * frame.shape[1]), int(y_center * frame.shape[0]))\n",
        "            input_centroids.append(centroid)\n",
        "\n",
        "            # Draw bounding boxes\n",
        "            x, y, w, h = int(xmin * frame.shape[1]), int(ymin * frame.shape[0]), int((xmax - xmin) * frame.shape[1]), int((ymax - ymin) * frame.shape[0])\n",
        "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
        "\n",
        "    # Use the CentroidTracker to track objects\n",
        "    tracked_objects = centroid_tracker.update(input_centroids)\n",
        "\n",
        "    for object_id, centroid in tracked_objects.items():\n",
        "        x, y = centroid  # Unpack the x and y coordinates from the centroid tuple\n",
        "        cv2.circle(frame, (x, y), 4, (0, 255, 0), -1)\n",
        "        cv2.putText(frame, f\"ID {object_id}\", (x - 10, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
        "\n",
        "    cv2_imshow(frame)  # Use cv2_imshow to display the frame\n",
        "\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "video_capture.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}